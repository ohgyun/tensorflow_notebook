{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.1159 [[ 0.89370596  0.46651766 -0.78151834]]\n",
      "20 0.790975 [[ 0.62105995  0.21844779 -0.2143227 ]]\n",
      "40 0.693292 [[ 0.32594696  0.02469599  0.04885299]]\n",
      "60 0.636145 [[ 0.04449177 -0.06727879  0.21108982]]\n",
      "80 0.594276 [[-0.22121522 -0.10808785  0.31814247]]\n",
      "100 0.560124 [[-0.47109437 -0.12221042  0.39375275]]\n",
      "120 0.530975 [[-0.70588577 -0.12199079  0.45061204]]\n",
      "140 0.505586 [[-0.92662424 -0.11406019  0.49587554]]\n",
      "160 0.483235 [[-1.13442075 -0.10213612  0.53374112]]\n",
      "180 0.46342 [[-1.33037007 -0.08834643  0.56673753]]\n",
      "200 0.445758 [[-1.51550615 -0.07391274  0.59641564]]\n",
      "220 0.429937 [[-1.69078588 -0.0595265   0.62374085]]\n",
      "240 0.4157 [[-1.85708296 -0.04556627  0.64932317]]\n",
      "260 0.402832 [[-2.01518798 -0.03222535  0.67355531]]\n",
      "280 0.391153 [[-2.16581321 -0.01958843  0.69669563]]\n",
      "300 0.380508 [[-2.30959821 -0.00767756  0.71891934]]\n",
      "320 0.370769 [[-2.44711685  0.00352044  0.74034941]]\n",
      "340 0.361826 [[-2.57888293  0.01403701  0.76107556]]\n",
      "360 0.353584 [[-2.70535779  0.02391273  0.78116602]]\n",
      "380 0.345965 [[-2.82695365  0.0331912   0.80067456]]\n",
      "400 0.338897 [[-2.94404387  0.04191621  0.81964564]]\n",
      "420 0.332323 [[-3.05696201  0.05012969  0.83811659]]\n",
      "440 0.32619 [[-3.1660099   0.0578709   0.85611981]]\n",
      "460 0.320453 [[-3.27146053  0.06517641  0.87368399]]\n",
      "480 0.315074 [[-3.37356067  0.07207951  0.89083505]]\n",
      "500 0.310017 [[-3.47253418  0.07861071  0.90759593]]\n",
      "520 0.305254 [[-3.5685842   0.08479776  0.92398793]]\n",
      "540 0.300758 [[-3.66189718  0.09066598  0.94003069]]\n",
      "560 0.296504 [[-3.75264144  0.09623814  0.95574218]]\n",
      "580 0.292473 [[-3.84097242  0.10153519  0.97113907]]\n",
      "600 0.288645 [[-3.92703295  0.10657617  0.98623693]]\n",
      "620 0.285005 [[-4.01095295  0.11137839  1.00105   ]]\n",
      "640 0.281537 [[-4.09285164  0.11595751  1.01559186]]\n",
      "660 0.278228 [[-4.1728406   0.12032817  1.02987492]]\n",
      "680 0.275066 [[-4.25102186  0.12450354  1.04391098]]\n",
      "700 0.272041 [[-4.32749033  0.12849563  1.05771101]]\n",
      "720 0.269142 [[-4.40233374  0.13231574  1.07128537]]\n",
      "740 0.266361 [[-4.47563171  0.13597396  1.08464348]]\n",
      "760 0.26369 [[-4.54746103  0.1394798   1.09779477]]\n",
      "780 0.261121 [[-4.61789274  0.1428421   1.11074734]]\n",
      "800 0.258648 [[-4.68699217  0.14606887  1.12350988]]\n",
      "820 0.256265 [[-4.75482035  0.14916752  1.13608944]]\n",
      "840 0.253966 [[-4.82143497  0.15214522  1.14849317]]\n",
      "860 0.251746 [[-4.88688803  0.15500811  1.16072786]]\n",
      "880 0.2496 [[-4.95123196  0.15776245  1.17280006]]\n",
      "900 0.247524 [[-5.01451206  0.16041338  1.18471575]]\n",
      "920 0.245514 [[-5.07677412  0.16296653  1.19648051]]\n",
      "940 0.243566 [[-5.13805962  0.16542663  1.20809984]]\n",
      "960 0.241677 [[-5.19840622  0.1677981   1.21957898]]\n",
      "980 0.239844 [[-5.25785208  0.17008521  1.23092258]]\n",
      "1000 0.238063 [[-5.316432    0.17229213  1.24213541]]\n",
      "1020 0.236333 [[-5.37417841  0.17442234  1.25322151]]\n",
      "1040 0.23465 [[-5.4311223   0.17647956  1.26418543]]\n",
      "1060 0.233012 [[-5.48729372  0.17846692  1.27503097]]\n",
      "1080 0.231417 [[-5.54272127  0.18038769  1.28576195]]\n",
      "1100 0.229863 [[-5.59743023  0.18224473  1.29638207]]\n",
      "1120 0.228348 [[-5.65144587  0.18404073  1.30689454]]\n",
      "1140 0.22687 [[-5.7047925   0.18577841  1.31730294]]\n",
      "1160 0.225427 [[-5.75749254  0.18746004  1.32761025]]\n",
      "1180 0.224018 [[-5.80956697  0.18908805  1.33781946]]\n",
      "1200 0.222641 [[-5.86103725  0.19066456  1.34793341]]\n",
      "1220 0.221296 [[-5.91192055  0.19219156  1.35795486]]\n",
      "1240 0.21998 [[-5.96223831  0.19367129  1.36788642]]\n",
      "1260 0.218692 [[-6.01200819  0.19510573  1.37773061]]\n",
      "1280 0.217432 [[-6.06124544  0.19649634  1.3874898 ]]\n",
      "1300 0.216197 [[-6.10996675  0.1978448   1.39716625]]\n",
      "1320 0.214988 [[-6.15818787  0.19915302  1.40676236]]\n",
      "1340 0.213803 [[-6.20592403  0.2004222   1.41628015]]\n",
      "1360 0.212641 [[-6.25318766  0.20165384  1.42572153]]\n",
      "1380 0.211501 [[-6.29999399  0.20284952  1.4350884 ]]\n",
      "1400 0.210383 [[-6.34635496  0.20401034  1.44438303]]\n",
      "1420 0.209285 [[-6.39228296  0.2051376   1.45360684]]\n",
      "1440 0.208208 [[-6.43778992  0.20623238  1.46276188]]\n",
      "1460 0.207149 [[-6.48288774  0.2072961   1.47184932]]\n",
      "1480 0.206109 [[-6.52758789  0.20832977  1.48087132]]\n",
      "1500 0.205087 [[-6.57189608  0.20933408  1.48982882]]\n",
      "1520 0.204082 [[-6.61582994  0.2103107   1.49872398]]\n",
      "1540 0.203094 [[-6.65939522  0.21126002  1.50755787]]\n",
      "1560 0.202122 [[-6.70260143  0.21218319  1.51633191]]\n",
      "1580 0.201165 [[-6.74545765  0.21308109  1.52504754]]\n",
      "1600 0.200224 [[-6.78797293  0.21395448  1.53370595]]\n",
      "1620 0.199297 [[-6.83015537  0.21480417  1.54230845]]\n",
      "1640 0.198384 [[-6.87201214  0.21563087  1.55085611]]\n",
      "1660 0.197485 [[-6.91355133  0.21643543  1.55935013]]\n",
      "1680 0.196599 [[-6.95478106  0.21721844  1.56779182]]\n",
      "1700 0.195726 [[-6.99570799  0.21798073  1.57618201]]\n",
      "1720 0.194866 [[-7.03633976  0.21872286  1.58452201]]\n",
      "1740 0.194018 [[-7.07668066  0.21944521  1.59281266]]\n",
      "1760 0.193181 [[-7.11674118  0.22014883  1.60105526]]\n",
      "1780 0.192356 [[-7.15652418  0.22083406  1.60925031]]\n",
      "1800 0.191542 [[-7.19603682  0.22150163  1.61739862]]\n",
      "1820 0.190739 [[-7.23528528  0.22215195  1.62550163]]\n",
      "1840 0.189947 [[-7.27427483  0.22278546  1.63355982]]\n",
      "1860 0.189164 [[-7.31301022  0.22340284  1.64157414]]\n",
      "1880 0.188392 [[-7.35149717  0.22400442  1.64954531]]\n",
      "1900 0.187629 [[-7.38974094  0.22459058  1.65747428]]\n",
      "1920 0.186876 [[-7.4277463   0.225162    1.66536176]]\n",
      "1940 0.186131 [[-7.465518    0.22571902  1.67320824]]\n",
      "1960 0.185396 [[-7.50306129  0.22626193  1.6810149 ]]\n",
      "1980 0.18467 [[-7.54038     0.22679128  1.68878233]]\n",
      "2000 0.183952 [[-7.57747793  0.22730747  1.69651079]]\n",
      "--------------------\n",
      "[[False]]\n",
      "[[ True]]\n",
      "[[False]]\n",
      "[[False  True]]\n"
     ]
    }
   ],
   "source": [
    "# Logistic classification (Binary classification)\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "xy = np.loadtxt('/data/05.txt', unpack=True, dtype='float32')\n",
    "\n",
    "# x0: bias\n",
    "# x1: hours spent studying\n",
    "# x2: number of attendance\n",
    "# y: does pass the exam?\n",
    "x_data = xy[0:-1]\n",
    "y_data = xy[-1]\n",
    "\n",
    "X = tf.placeholder(tf.float32)\n",
    "Y = tf.placeholder(tf.float32)\n",
    "\n",
    "W = tf.Variable(tf.random_uniform([1, len(x_data)], -1.0, 1.0))\n",
    "\n",
    "# Our hypothesis: H(X) = WX\n",
    "h = tf.matmul(W, X)\n",
    "\n",
    "# Hypotheis for logistic classification (Sigmoid)\n",
    "#   H(X) = 1 / 1 + e^(-WX)\n",
    "#\n",
    "# Tensorflow already has sigmoid function,\n",
    "# but we try to implement it for study.\n",
    "hypothesis = tf.div(1., 1. + tf.exp(-h))\n",
    "\n",
    "# Cost function\n",
    "# cost(W) = -1/m * sum(ylog(H(x)) + (1-y)log(1-H(x)))\n",
    "cost = -tf.reduce_mean(Y * tf.log(hypothesis) + (1-Y) * tf.log(1-hypothesis))\n",
    "\n",
    "# Minimize\n",
    "a = tf.Variable(0.1) # Learning rate, alpha\n",
    "optimizer = tf.train.GradientDescentOptimizer(a)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "init = tf.initialize_all_variables()\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "# Start training\n",
    "for step in xrange(2001):\n",
    "    sess.run(train, feed_dict={X: x_data, Y: y_data})\n",
    "    if step % 20 == 0:\n",
    "        print step, sess.run(cost, feed_dict={X: x_data, Y: y_data}), sess.run(W)\n",
    "\n",
    "print '--------------------'\n",
    "\n",
    "# Now, our model got trained.\n",
    "# Let's predict using other data.\n",
    "# The values in X are [[bias=1], [study hour], [attendance]],\n",
    "# and if result, the Y, is bigger than 0.5 then it means that he will pass the exam.\n",
    "print sess.run(hypothesis, feed_dict={X:[[1], [2], [2]]}) > 0.5\n",
    "print sess.run(hypothesis, feed_dict={X:[[1], [1], [5]]}) > 0.5\n",
    "print sess.run(hypothesis, feed_dict={X:[[1], [7], [1]]}) > 0.5\n",
    "\n",
    "# Ask with data of 2 people\n",
    "print sess.run(hypothesis, feed_dict={X:[[1, 1], [10, 0], [0, 10]]}) > 0.5 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
